---
title: "Project 2 Report"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Group Members (names and EIDs): Ria Bhatia (rnb982) & Ethan Benson (erb2994)




## Introduction

*In order to learn more about the relationships in the data, we used multiple exploratory data analysis techniques. First, we conducted a PCA test, which was then used to product a rotation plot, eigenvalues plot, and a scatter plot.*



```{r}
# Data exploration
library(tidyverse)
library(broom)

dat <- read_csv("pm25_data.csv.gz")


dat_clean <- dat |>
  select(-id) |>
  select(where(is.numeric))

# Scatter plot of CMAQ vs AOD
dat_clean |> 
  ggplot(aes(CMAQ, aod)) +
  geom_point(color = "darkgreen") +
  theme_classic() +
  labs(
    title = "CMAQ vs AOD",
    x = "CMAQ",
    y = "AOD"
  ) +
  theme(
    plot.title = element_text(face = "bold")
  )

# PCA
pca_fit <- dat_clean |> 
  select(where(is.numeric)) |> 
  scale() |> 
  prcomp()
pca_fit

# Rotation plot
arrow_style <- arrow(
  angle = 20, length = grid::unit(8, "pt"),
  ends = "first", type = "closed"
)

pca_fit |> 
  tidy(matrix = "rotation") |>   
  pivot_wider(
    names_from = "PC", values_from = "value",
    names_prefix = "PC"
  ) |> 
  ggplot(aes(PC1, PC2)) +
  geom_segment(
    xend = 0, yend = 0,
    arrow = arrow_style
  ) +
  geom_text(aes(label = column)) +
  coord_fixed() +
  labs(
    title = "Rotation Plot of PC 1 vs PC 2"
  ) + xlim(-.4, .6) 

# Eigenvalues plot
pca_fit |> 
  tidy(matrix = "eigenvalues") |> 
  ggplot(aes(PC, percent)) +
  geom_col() +
  scale_x_continuous() +
  scale_y_continuous(labels = scales::label_percent()) +
  labs(
    title = "Eigenvalues Plot of Principle Components"
  )

# Scatter plot
pca_fit |> 
  augment(dat_clean) |> 
  ggplot(aes(x = .fittedPC1, y = .fittedPC2, color = dat_clean$value)) +
  geom_point() +
  labs(
    title = "PC 2 vs PC 1 by Average PM2.5 Levels",
    x = "PC 1",
    y = "PC 2"
  ) +
  theme_grey() +
  theme(
    plot.title = element_text(face = "bold")
  ) +
  coord_fixed()

```


## Data Wrangling

```{r}

library(tidymodels)

dat <- read_csv("pm25_data.csv.gz")


dat_clean <- dat |>
  select(-id) |>
  select(where(is.numeric))

dat_split <- initial_split(dat_clean)

#Split into train and test
dat_train <- training(dat_split)
dat_test <- testing(dat_split)

#Linear Regression Model
rec <- dat_train |>
    recipe(value ~ .)

model <- linear_reg() |> 
    set_engine("lm") |> 
    set_mode("regression")

wf <- workflow() |> 
    add_recipe(rec) |> 
    add_model(model)

folds <- vfold_cv(dat_train, v = 10)

res_lin <- wf |> 
    fit_resamples(resamples = folds)
res_lin |> 
    collect_metrics()

```

```{r}

# Logistical Regression Model - Ethan
```


```{r}

# kNN

rec <- dat_train |> 
    recipe(value ~ .) |> 
    step_normalize() 

## Tune for the optimal number of neighbors
model <- nearest_neighbor(neighbors = tune("k")) |> 
    set_engine("kknn") |> 
    set_mode("regression")
wf <- workflow() |> 
    add_model(model) |> 
    add_recipe(rec)
wf

folds <- vfold_cv(dat_train, v = 10)

res <- tune_grid(wf, resamples = folds,
                 grid = tibble(k = c(10, 12, 13, 15, 17, 18, 20, 25)))

res |> 
    collect_metrics()

res |> 
    collect_metrics() |> 
    filter(.metric == "rmse") |> 
    ggplot(aes(k, mean)) +
    geom_point() + 
    geom_line()

res |> 
    show_best(metric = "rmse")

# Evaluate model with best k = 12

model <- nearest_neighbor(neighbors = 12) |> 
    set_engine("kknn") |> 
    set_mode("regression")

wf <- workflow() |> 
    add_model(model) |> 
    add_recipe(rec)
wf

folds <- vfold_cv(dat_train, v = 10)

res <- fit_resamples(wf, resamples = folds)

res |> 
    collect_metrics()

```

```{r}
library(ranger)
# Random Forest
rec <- dat_train |> 
    recipe(value ~ .) |> 
    step_normalize() 

model <- rand_forest(mtry = tune("mtry"),
                     min_n = tune("min_n")) |> 
    set_engine("ranger") |> 
    set_mode("regression")

wf <- workflow() |> 
    add_recipe(rec) |> 
    add_model(model)

## Fit model over grid of tuning parameters
res <- tune_grid(wf, resamples = folds, 
                 grid = expand.grid(mtry = c(1, 2, 5),
                                    min_n = c(3, 5)))
#res |> 
    #collect_metrics()

res |> 
    show_best(metric = "rmse")

#res |> 
    #show_best(metric = "rsq")


## Fit the best model obtained from tuning
model <- rand_forest(mtry = 5,
                     min_n = 3) |> 
    set_engine("ranger") |> 
    set_mode("regression")

wf <- workflow() |> 
    add_recipe(rec) |> 
    add_model(model)

## Final model fit
final <- wf |> 
    last_fit(split = dat_split)

final |> 
    collect_metrics()

```


## Results

```{r}
# Output all RMSE for each model - Ethan

# Predict using final model on dat_test


# Scatter plot of predicted vs observed data points

```


```{r}

# Any code for primary questions

```
## Discussion