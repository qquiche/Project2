---
title: "Project 2 Report"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Group Members (names and EIDs): Ria Bhatia (rnb982) & Ethan Benson (erb2994)




## Introduction

*For our comparison, we chose the following modeling approaches: linear regression, neural net (multilayer perception), kNN, and random forest. With these models, we used all of the available predictors, so we could truly understand the relationship between each predictor and the observations. In order to learn more about the relationships in the data, we used multiple exploratory data analysis techniques. First, we created a scatter plot to understand the relationship between CMAQ and AOD. Second, we conducted a PCA test, which was then used to produce a rotation plot, eigenvalues plot, and scatter plot. After creating the models and conducting exploratory analysis, we hypothesized that either neural nets or random forest would be the best model. This would be because random forest incorporates assembling and neural nets can be tuned a lot, which is very helpful since we have many inputs.*



```{r}
# Reading in the libraries and data set
library(tidyverse)
library(broom)

dat <- read_csv("pm25_data.csv.gz")

dat_clean <- dat |> # Cleaning the data set
  select(-id) |>
  select(where(is.numeric))
```

```{r}
# Data exploration

# Scatter plot of CMAQ vs AOD
dat_clean |> 
  ggplot(aes(CMAQ, aod)) +
  geom_point(color = "darkgreen") +
  theme_classic() +
  labs(
    title = "CMAQ vs AOD",
    x = "CMAQ",
    y = "AOD"
  ) +
  theme(
    plot.title = element_text(face = "bold")
  )
```

```{r}
# Data exploration continued - PCA

# PCA
pca_fit <- dat_clean |> 
  select(where(is.numeric)) |> 
  scale() |> 
  prcomp()
pca_fit

# Rotation plot
arrow_style <- arrow(
  angle = 20, length = grid::unit(8, "pt"),
  ends = "first", type = "closed"
)

pca_fit |> 
  tidy(matrix = "rotation") |>   
  pivot_wider(
    names_from = "PC", values_from = "value",
    names_prefix = "PC"
  ) |> 
  ggplot(aes(PC1, PC2)) +
  geom_segment(
    xend = 0, yend = 0,
    arrow = arrow_style
  ) +
  geom_text(aes(label = column)) +
  coord_fixed() +
  labs(
    title = "Rotation Plot of PC 1 vs PC 2"
  ) + xlim(-.4, .6) 

# Eigenvalues plot
pca_fit |> 
  tidy(matrix = "eigenvalues") |> 
  ggplot(aes(PC, percent)) +
  geom_col() +
  scale_x_continuous() +
  scale_y_continuous(labels = scales::label_percent()) +
  labs(
    title = "Eigenvalues Plot of Principle Components"
  )

# Scatter plot
pca_fit |> 
  augment(dat_clean) |> 
  ggplot(aes(x = .fittedPC1, y = .fittedPC2, color = dat_clean$value)) +
  geom_point() +
  labs(
    title = "PC 2 vs PC 1 by Average PM2.5 Levels",
    x = "PC 1",
    y = "PC 2"
  ) +
  theme_grey() +
  theme(
    plot.title = element_text(face = "bold")
  ) +
  coord_fixed()  +
  scale_color_gradient(low = "blue", high = "red", breaks = c(0, 10, 20, 30))

```


## Data Wrangling

```{r}

library(tidymodels)

dat <- read_csv("pm25_data.csv.gz")

dat_split <- initial_split(dat_clean)

#Split into train and test
dat_train <- training(dat_split)
dat_test <- testing(dat_split)
```

```{r}
#Linear Regression Model
rec <- dat_train |>
    recipe(value ~ .)

model <- linear_reg() |> 
    set_engine("lm") |> 
    set_mode("regression")

wf <- workflow() |> 
    add_recipe(rec) |> 
    add_model(model)

folds <- vfold_cv(dat_train, v = 10)

lin_final <- wf |> 
    fit_resamples(resamples = folds)

res_lin <- lin_final |> 
    collect_metrics()

```

```{r}

# Neural Net (Multilayer Perceptron)
rec <- dat_train |> 
    recipe(value ~ .) |> 
    step_normalize() 

model <- mlp(hidden_units = tune(), penalty = tune(),
             epochs = tune()) |> 
  set_engine("nnet") |> 
  set_mode("regression")

wf <- workflow() |> 
    add_model(model) |> 
    add_recipe(rec)

mlp_grid <- expand.grid(
  hidden_units = c(5, 10, 15),
  penalty = c(0, 0.01, 0.1),
  epochs = c(10, 50, 100)
)

folds <- vfold_cv(dat_train, v = 10)

res <- tune_grid(wf, resamples = folds, grid = mlp_grid)

res |> 
    show_best(metric = "rmse")

## Fit the best model obtained from tuning
model <- mlp(hidden_units = 10, penalty = .1,
             epochs = 50) |> 
  set_engine("nnet") |> 
  set_mode("regression")

wf <- workflow() |> 
    add_recipe(rec) |> 
    add_model(model)

## Neural Net Final model fit
NN_final <- wf |> 
    last_fit(split = dat_split)

res_NN <- NN_final |> 
    collect_metrics()

```


```{r}

# kNN

rec <- dat_train |> 
    recipe(value ~ .) |> 
    step_normalize()

## Tune for the optimal number of neighbors
model <- nearest_neighbor(neighbors = tune("k")) |> 
    set_engine("kknn") |> 
    set_mode("regression")
wf <- workflow() |> 
    add_model(model) |> 
    add_recipe(rec)

folds <- vfold_cv(dat_train, v = 10)

res <- tune_grid(wf, resamples = folds,
                 grid =tibble(k = c(10, 12, 13, 15, 17, 18, 20, 25)))

res |> 
    show_best(metric = "rmse")

# Evaluate model with best k = 12
rec <- dat_train |> 
    recipe(value ~ .) |> 
    step_normalize()

model <- nearest_neighbor(neighbors = 12) |> 
    set_engine("kknn") |> 
    set_mode("regression")

wf <- workflow() |> 
    add_recipe(rec) |> 
    add_model(model)

## Final model fit
kNN_final <- wf |> 
    last_fit(split = dat_split)

res_kNN <- kNN_final |> 
    collect_metrics()

```

```{r}
library(ranger)
# Random Forest
rec <- dat_train |> 
    recipe(value ~ .) |> 
    step_normalize() 

model <- rand_forest(mtry = tune("mtry"),
                     min_n = tune("min_n")) |> 
    set_engine("ranger") |> 
    set_mode("regression")

wf <- workflow() |> 
    add_recipe(rec) |> 
    add_model(model)

## Fit model over grid of tuning parameters
res <- tune_grid(wf, resamples = folds, 
                 grid = expand.grid(mtry = c(1, 2, 5),
                                    min_n = c(3, 5)))

res |> 
    show_best(metric = "rmse")


## Fit the best model obtained from tuning
model <- rand_forest(mtry = 5,
                     min_n = 3) |> 
    set_engine("ranger") |> 
    set_mode("regression")

wf <- workflow() |> 
    add_recipe(rec) |> 
    add_model(model)

## Final model fit
randFor_final <- wf |> 
    last_fit(split = dat_split)

res_rf <-randFor_final |> 
    collect_metrics()

```


## Results

```{r}
# Output all RMSE for each model - Ethan
# Linear Model Metrics
res_lin

# Neural net Metrics
res_NN

# kNN Metrics
res_kNN

# Random Forest Metrics
res_rf

# Prep dat_test
dat_test <- rec |> 
    prep() |> 
    bake(new_data = testing(dat_split))

# Scatter plot of predicted vs observed data points
randFor_final |> 
    extract_fit_parsnip() |> 
    augment(new_data = dat_test) |> 
    select(value, .pred) |> 
    ggplot(aes(.pred, value)) + 
    geom_point(alpha = 1/10)
```


```{r}
# Code for primary questions

# Question 1: Geographic locations

```

```{r}
# Question 2: Variables

```

```{r}
# Question 3: CMAQ & AOD

```

## Discussion

*It is notable that the data set does not include data from Alaska or Hawaii. We believe that the model would not perform as well due to Alaska and Hawaii both having significantly different environments compared to the rest of the states. On one hand, Alaska is much colder can the rest of the states, which can lead to different air quality patterns. On the other hand, Hawaii tends to have warmer weather conditions and is surrounded by a body of water, leading to differing air quality patterns as well. *

*In the process of conducting this process, we faced challenges in choosing appropriate models to conduct our analysis. For instance, in the beginning, we wanted to include a logistic regression model, which did not end up being feasible for our analysis.*
